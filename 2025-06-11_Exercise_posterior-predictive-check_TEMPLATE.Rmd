---
title: "m&m's exercise: Posterior Predictive Checking"
author: "Prof. Gwen Eadie"
date: "11/06/2025"
output: html_document
---


### Reminder of set-up for m\&m's exercise
$$P(\theta|y) = \frac{P(y|\theta)P(\theta)}{P(y)}$$

We defined:

-  $\theta$ as the percentage of blue candies made at the factory
-  $y$ as the number of blue candies observed in our data

The likelihood for our model was the binomial distribution with parameter $\theta$:

$$p(y|\theta) \propto \theta^{y}(1-\theta)^{n-y}.$$

This is our likelihood for $y$ blue candies, given the percentage $\theta$ produced at the factory.

We used the conjugate prior to the binomial distribution --- the beta distribution --- to quantify your prior information on the percentage $\theta$ of blue candies made at the factory:
$$p(\theta) \propto \theta^{\alpha-1}(1-\theta)^{\beta-1}$$
We chose some hyperparameter values
```{r}
# my hyperprior parameters for alpha and beta
mya = 3 
myb = 12
```

Next, we collected our data, both individually, and as a class.
```{r}
# total number of trials per bag
n = 15

# class data, number of successes (blue m&m's) from each bag
classdata = c(2,3,1,5,3,2,4,4,4,4,6,2,3,5,5,4,1,2,4,4)

# class data, total number of successes (blues)
# yclass = 

# number of bags
# nbags = 

# total trials for class is number of trials for each student n=16 times number of students
# nclass = 
```


We calculated the posterior given your data and your prior distribution, and plotted it. Here is the code I wrote (commented out) if you want to use it.
```{r}
# set margins
par( mar = c(5,5,2,2))

# plot the posterior distribution


# add the prior distribution to the plot, to compare


# add a legend

```

### Exercise

Estimate the posterior predictive distribution and compare it to the distribution of successes (blue m&m's) from the class 

To calculate the posterior predictive distribution, follow these steps:

 *  draw a random value of $\theta$ from the posterior
 *  draw a $y$ (number of blue m&m's) from the likelihood (binomial distribution) given that value of $\theta$
 *  Repeat this many times.
 

```{r}
## simulte data from 500 students

# number of students/simulated observations
# nsims=

# object to store simulated observations
# yfuture = 

# draw a random theta given the posterior distribution we found in class
# thetatemp <- rbeta(......) 
  
# for each theta, draw a random y (number of blues) and store that. This should result in 500 observations of y (number of blues)
# yfuture <- rbinom(.....) 
```


Next, qualitatively compare the predicted distribution of successes (number of blues) to the distribution of successes for the whole class.

```{r}
# plot to compare real data to mock data

```






